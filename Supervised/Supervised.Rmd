---
title: 'Análisis Supervisado'
output:
  html_document:
    df_print: paged
---

# Fundamentos de Ingeniería de Datos - Análisis Supervisado

*(2020) José Andrés Pérez, Andrés Martínez*

# Introducción

En este análisis supervisado de datos tenemos como objetivo usar un dataset (ver [1]) correspondiente a un censo de la población activa de EEUU, donde en cada fila del conjunto de datos tenemos disponible información como el género, situación familiar, situación fiscal, educación recibida...

Como clase tenemos una variable categórica binaria que nos indica, para cada ejemplo (que comprende un grupo de personas con características comunes), si tiene unos ingresos brutos anuales superiores a los 50K dólares. En otras palabras, nos indica si ese grupo de personas ha alcanzado el éxito laboral y son capaces de vivir una vida económicamente cómoda.

Por lo tanto, estamos ante un problema de clasificación binaria que pretendemos atacar usando 3 modelos distintos para, finalmente, realizar una comparativa entre ellos vislumbrando las fortalezas y debilidades de cada uno de ellos.

Para este análisis de datos, hemos decidido utilizar las siguientes técnicas:
- Redes Neuronales
- Random Forest
- Support Vector Machine

# Paquetes utilizados

Primero, vamos a instalar los paquetes utilizados para este análisis de datos:

```{r}
#install.packages("dplyr")
#install.packages("plyr")
#install.packages("tidyr")
#install.packages("plotrix")
#install.packages("VIM")
#install.packages("DMwR")
#install.packages("Amelia")
#install.packages("ggplot2")

library(plyr)
library(dplyr)
library(tidyr)
library(plotrix)
library(VIM)
library(DMwR)
library(Amelia)
library(ggplot2)
```

# Preprocesamiento de los datos

## Carga y primer vistazo

Antes que nada, vamos a cargar el dataset con los datos a analizar y realizar un vistazo rápido de los mismos. Este primer paso puede ayudarnos a decidir la relevancia de las columnas y su significado.

```{r}
data <- read.csv("../Data/adult.csv")

dim(data)
head(data)
summary(data)
```

Primero vamos a explicar cada atributo para tener clara su intención:
- age: Edad media de los participantes de cada ejemplo
- workclass: variable categórica que indica la clase trabajadora. Puede tener los siguientes valores: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked
- fnlwgt: según [2], se trata del número de personas que se cree que representa cada fila
- education: variable categórica que indica el nivel educativo de cada muestra. Sus valores posibles son: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool
- education.num: asignación numérica al atributo education. Cuanto más alto sea este valor, mayor es el nivel educativo de la muestra
- marital.status: estado civil de la muestra. Los valores posibles son: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse
- occupation: describe el sector laboral de la muestra. En este dataset existen estos posibles valores: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm- clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces
- relationship: indica la situación familiar de la muestra. Los valores posibles son: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried
- race: variable categórica que indica la raza de cada ejemplo. Se han encontrado los siguientes valores: White, Asian-Pac-Islander, Amer-Indian-Eskimo,Black, other
- sex: género binario de la muestra. Contempla únicamente "Male" y "Female"
- capital.gain: expectativa de aumento de ingresos anuales en el siguiente año
- capital.loss: expectativa de pérdida de ingresos anuales en el siguiente año
- hours.per.week: número de horas trabajadas por semana
- native.country: indica el país de origen de la muestra
- income: la clase del dataset. Indica 2 posibles valores: <=50K o >50K

## Visualización de los datos

Primero, realicemos un diagrama de sectores para ver la predominancia de cada valor de la clase:

```{r}
income <- data %>% group_by(data$income) %>% tally()
slices <- income[[2]]
lbls <- income[[1]]
pie3D(slices, labels = lbls, explode = 0.1,
main = "Valores de la clase \"income\"")
```

Vemos que tenemos un balance en los valores de la clase coherente para realizar el análisis. Es decir, no tenemos un valor de la clase que sea muy poco común de encontrar.

Ahora, realicemos unos histogramas sobre varias columnas para observar el rango de valores de cada una de ellas:

```{r}
hist(data$age)
hist(data$fnlwgt)
hist(data$education.num)
```

Sobre estos histogramas podemos sacar varias conclusiones:
- La edad media de las muestras tiene un pico en los 20, 30 y 40 años, y va disminuyendo hasta los 80/90. Quizás deberíamos eliminar las filas con edad mayor a los 70 años porque pueden corresponder a casos muy raros que poco tengan que aportar al estudio
- Cada muestra tiene un censo variable que suele rondar las 100.000 personas, siendo muy infrecuente tener más de 500.000 personas en una muestra
- El nivel educativo tiene un gran pico en el nivel 8 y 9, que corresponden a personas que se han quedado en el curso 12th (no han terminado la secundaria pero casi), y personas que han terminado la secundaria pero no han continuado sus estudios
- Tenemos otro pico en el nivel 12 que corresponde a personas que han llegado a la universidad y han completado una carrera, pero no han continuado los estudios

A continuación, vamos a desglosar el dataset por sector productivo y nivel educativo para ver el número de horas trabajadas:

```{r}
qplot(workclass, hours.per.week, data=data, geom="boxplot", fill=workclass)+
  theme(plot.title=element_text(size=18),axis.text.x=element_text(angle=90,vjust=1))
qplot(education, hours.per.week, data=data, geom="boxplot", fill=education)+
  theme(plot.title=element_text(size=18),axis.text.x=element_text(angle=90,vjust=1))
```
Se ve que los autónomos son los que más horas trabajan a la semana, aunque también hay personas que no cobran y están siendo explotadas, trabajando casi 50 horas a la semana.

En cuanto al nivel educativo, podemos intuir que las personas con un nivel educativo universitario en adelante (máster, doctorado, profesores...) tienden a trabajar más horas a la semana.

Veamos si ese número extra de horas trabajadas tiene correlación con una mayor probabilidad de ganar 50K al año, mostrando esta información mediante diagramas de barras:

```{r}
bar1 <- data %>%
    mutate(ricos = (income == ">50K")) %>%
    group_by(workclass) %>%
    summarize(porcentaje = mean(ricos, na.rm = TRUE) * 100.0)
ggplot(data=bar1, aes(x=workclass, y=porcentaje)) + geom_bar(stat="identity")

bar2 <- data %>%
    mutate(ricos = (income == ">50K")) %>%
    group_by(education) %>%
    summarize(porcentaje = mean(ricos, na.rm = TRUE) * 100.0)
ggplot(data=bar2, aes(x=education, y=porcentaje)) + geom_bar(stat="identity")
```
Y, como sería coherente, el sector autónomo tiene mayor posibilidad de ganar más de 50K al año debido a su mayor número de horas trabajadas semanales.

Si nos fijamos en el diagrama de barras que clasifica por nivel educativo, aquellas personas que tienen estudios superiores a una carrera universitaria (máster y doctorado) y los profesores tienen mayor probabilidad de tener la vida resuelta. Qué suerte que nos encontramos en ese grupo.

Para finalizar, vamos a analizar la edad en cuanto a conseguir el objetivo de ganar 50K al año:

```{r}
bar3 <- data %>% 
  group_by(income, age) %>% 
  tally() %>% 
  complete(age, fill = list(n = 0)) %>% 
  mutate(percentage = n / sum(n) * 100)
ggplot(bar3, aes(age, percentage, fill = income)) + 
  geom_bar(stat = 'identity', position = 'dodge') +
  theme_bw()
```
Donde observamos que antes de los 25 años es bastante improbable conseguir tener esos ingresos anuales (por ejemplo puede deberse a la falta de experiencia), aunque a medida que pasan los años se incrementan sustancialmente las posibilidades, encontrando  un pico entre los 35-45 años, rango de edad donde aún no se es demasiado mayor y se tiene mucha experiencia adquirida.

## Simplificación de atributos

Comencemos renombrando los atributos para que sean más legibles:

```{r}
prepro <- data
names(prepro)[3] <- "people_sample"
names(prepro)[5] <- "education_num"
names(prepro)[6] <- "marital_status"
names(prepro)[11] <- "capital_gain"
names(prepro)[12] <- "capital_loss"
names(prepro)[13] <- "hours_per_week"
names(prepro)[14] <- "native_country"
```

Ahora, podemos eliminar el atributo education_num estableciendo un orden al atributo education, y el atributo people_sample debido a que no proporciona información relevante para realizar la clasificación:

```{r}
education_order <- c("Preschool", "1st-4th", "5th-6th", "7th-8th", "9th", "10th", "11th", "12th", "HS-grad", "Some-college", "Assoc-voc", "Assoc-acdm", "Bachelors", "Masters", "Prof-school", "Doctorate")
prepro$education <- factor(prepro$education, ordered = TRUE, levels = education_order)
prepro$education_num <- NULL
prepro$people_sample <- NULL
```

De igual manera, podemos asignar el valor 0 a ganar menor o igual a 50K anuales, y el valor 1 para el caso contrario. También podemos convertir el resto de atributos tipo texto a variables categóricas:

```{r}
prepro$moreThan50K <- mapvalues(prepro$income, from = c(">50K","<=50K"), to = c(1, 0))
prepro$moreThan50K <- strtoi(prepro$moreThan50K)
prepro$income <- NULL
prepro$workclass <- as.factor(prepro$workclass)
prepro$marital_status <- as.factor(prepro$marital_status)
prepro$occupation <- as.factor(prepro$occupation)
prepro$relationship <- as.factor(prepro$relationship)
prepro$race <- as.factor(prepro$race)
prepro$sex <- as.factor(prepro$sex)
prepro$native_country <- as.factor(prepro$native_country)
head(prepro)
```

## Tratamiento de los valores perdidos

Ahora, veamos cuántos valores perdidos tenemos. Al observar el dataset detenidamente, se ha llegado a la conclusión de que los valores perdidos se identifican con una "?" en las variables tipo texto y categóricas. Por lo tanto, vamos a sustituirlos por valores NA:

```{r}
colSums(is.na(prepro))
prepro[prepro == "?"] <- NA
colSums(is.na(prepro))
```
Observemos los valores perdidos realizando un gráfico para hacernos una idea de su distribución:

```{r}
fig <- function(w, h){
     options(repr.plot.width = w, repr.plot.height = h)
}

fig(15,15)
missmap(prepro, rank.order = FALSE, col = c(0,1), legend = FALSE)
```
Echando un vistazo al diagrama anterior, podemos concluir que los valores perdidos se concrentan principalmente en 3 columnas: workclass, occupation y native_country.

Para eliminar los valores perdidos, vamos a aplicar varias técnicas y ver cuál de ellas nos da un mejor resultado. Primero, vamos a eliminar todas las filas que contengan algún valor perdido:

```{r}
prepro_withoutNA <- prepro %>% drop_na()
colSums(is.na(prepro_withoutNA))
```
A continuación, vamos a usar el algoritmo KNN para, en vez de eliminar las filas directamente, sustituir los valores perdidos por la media del valor de los k vecinos más cercanos:

```{r}
#Dataset rellenando valores con Knn
prepro_knn <- kNN(prepro, variable = colnames(prepro))
#prepro_knn <- subset(prepro_knn, select = -c(16:30))
colSums(is.na(data))
head(prepro_knn)
```

## Eliminación de casos raros / imposibles

Anteriormente vimos que en ciertos aspectos el dataset tiene ejemplos un tanto desbalanceados, por ejemplo en la edad de las muestras, donde teníamos filas de edad media superior a los 90 años. Para lidiar con estos casos y otros que se nos puedan escapar, vamos a aplicar el algoritmo SMOTE:

```{r}
prepro <- SMOTE(moreThan50K ~ ., prepro, perc.over=100)
dim(prepro)
```

# Redes Neuronales

## Introducción teórica

## Preprocesamiento adicional

Meter la normalización que hacía falta para redes neuronales

```{r}
prepro_neural <- prepro
prepro_neural <- prepro_neural %>% mutate_if(is.numeric, scale)
head(prepro_neural)
```

## Entrenamiento del modelo

## Validación del modelo

### Cálculo de valores de bondad

# Random Forest

## Introducción teórica

## Preprocesamiento adicional

## Entrenamiento del modelo

## Validación del modelo

### Cálculo de valores de bondad

# Support Vector Machine

https://www.kaggle.com/ameyadalal/income-classification-with-svm-and-logistics

## Introducción teórica

## Entrenamiento del modelo

## Validación del modelo

### Cálculo de valores de bondad

# Comparativa entre los modelos

# Conclusiones

# Bibliografía

[1] Dataset: https://www.kaggle.com/uciml/adult-census-income
[2] Parámetro fnlwgt: https://www.kaggle.com/uciml/adult-census-income/discussion/32698
